{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Reidentifaction Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple example that performs a reidentification attack on network data and synthetically generated network data.<br>\n",
    "Example based on smarnoise-samples/whitepaper-demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder containg data csv\n",
    "dataPath = '../data/New_NETWORK_TEST/NEW_NETWORK_TEST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "# assume attack has the entire original network dataset\n",
    "def readCSV(data, drop=None):\n",
    "    # data is the path of the csv file\n",
    "    try:\n",
    "        df_data = pd.read_csv(data, sep=\",\", encoding=\"utf-8\").infer_objects()\n",
    "        if drop:\n",
    "            try:\n",
    "                df_data = df_data.drop(drop, axis=1)\n",
    "            except:\n",
    "                print(f'Cannot drop column {drop} from dataframe. Column {drop} not found')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        df_data = None\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a df of indices of potential matches (matches), the original and synthethic data,\n",
    "# return a dataframe of the appropriate rows from original and synth\n",
    "def get_matches(matches, original, synth):\n",
    "    col = pd.concat([pd.Series('index_original'), pd.Series(original.columns+'_original'), pd.Series('index_synth'), pd.Series(synth.columns+'_synth')]) \n",
    "    match_data = pd.DataFrame(columns=col)\n",
    "    for index, row in matches.iterrows():\n",
    "        original_row = [row[0]] + original.iloc[row[0],:].tolist()\n",
    "        synth_row = [row[1]] + synth.iloc[row[1],:].tolist()       \n",
    "        temp = pd.DataFrame([original_row + synth_row], columns=col)\n",
    "        match_data = pd.concat([match_data, temp])\n",
    "        \n",
    "    return match_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_reidentification_noise(synth, net):\n",
    "    col = pd.concat([pd.Series('index_original'), pd.Series(net.columns+'_original'), pd.Series('index_synth'), pd.Series(synth.columns+'_synth')]) \n",
    "   \n",
    "    reident_50 = pd.DataFrame(columns=['index_original', 'index_synth']) # 50% match\n",
    "    reident_75 = pd.DataFrame(columns= ['index_original', 'index_synth']) # 75% match\n",
    "    reident_100 = pd.DataFrame(columns= ['index_original', 'index_synth']) # 100% match\n",
    "    \n",
    "    num_columns = len(net.columns)\n",
    "    percent_50 = int(np.round(num_columns/2)) # num of matched columns for 50%\n",
    "    percent_75 = int(np.round((3*num_columns)/4)) # num of matched columns for 75%\n",
    "\n",
    "    for index1, row1 in tqdm(net.iterrows(), total=net.shape[0]):\n",
    "            # Here list all columns that are needed for reidentification\n",
    "            # will try to find a match between rows in the synthetic data and the information\n",
    "            # the attacker has (original network dataset)\n",
    "            for index2, row2 in synth.iterrows():\n",
    "                # get the num of columns that match for row1 and row2\n",
    "                # with wildcard (nan) matching included\n",
    "                def calculate_match(row1, row2):\n",
    "                    return sum([\n",
    "                        int((pd.isna(row1[col])) or (row1[col] == row2[col]))\n",
    "                        for col in row1.index\n",
    "                        ])\n",
    "                #match = sum((row1 == row2).astype(int).tolist())\n",
    "                match = calculate_match(row1, row2)\n",
    "                \n",
    "                # determine possible reidentification\n",
    "                # Don't double count, i.e. match of 75% will not appera as match of > 25%\n",
    "                if match == num_columns:\n",
    "                    temp = pd.DataFrame([[index1, index2]], columns=['index_original', 'index_synth'])\n",
    "                    reident_100 = pd.concat([reident_100, temp])\n",
    "                elif match >= percent_75:\n",
    "                    temp = pd.DataFrame([[index1, index2]], columns=['index_original', 'index_synth'])\n",
    "                    reident_75 = pd.concat([reident_75, temp])\n",
    "                elif match >= percent_50:\n",
    "                    temp = pd.DataFrame([[index1, index2]], columns=['index_original', 'index_synth'])\n",
    "                    reident_50 = pd.concat([reident_50, temp])\n",
    "    \n",
    "    print(f\"Identified {len(reident_100)} potential matches (100%)!\")\n",
    "    print(f\"Identified {len(reident_75)} potential matches (75%)!\")\n",
    "    print(f\"Identified {len(reident_50)} potential matches (50%)!\")\n",
    "    return reident_100, reident_75, reident_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = readCSV(dataPath+'original.csv', drop='Attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan_1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d251e9ed4c36427eb3bf38299514ea15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 103 potential matches (75%)!\n",
      "Identified 13625 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "ctgan_1 = readCSV(dataPath+'ctgan_1.csv', drop='Attack')\n",
    "ctgan_1_attack_100, ctgan_1_attack_75, ctgan_1_attack_50 = try_reidentification_noise(ctgan_1, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_gan_1_attack_50_matches = get_matches(ctgan_1_attack_50, original, ctgan_1)\n",
    "ct_gan_1_attack_75_matches = get_matches(ctgan_1_attack_75, original, ctgan_1)\n",
    "ct_gan_1_attack_100_matches = get_matches(ctgan_1_attack_100, original, ctgan_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan_2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ebf9759e5b4a15a4e3a0e3a52b505b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 217 potential matches (75%)!\n",
      "Identified 27888 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "ctgan_2 = readCSV(dataPath+'ctgan_2.csv')\n",
    "ctgan_2_attack_100, ctgan_2_attack_75, ctgan_2_attack_50 = try_reidentification_noise(ctgan_2, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_2_attack_50_matches = get_matches(ctgan_2_attack_50, original, ctgan_2)\n",
    "ctgan_2_attack_75_matches = get_matches(ctgan_2_attack_75, original, ctgan_2)\n",
    "ctgan_2_attack_100_matches = get_matches(ctgan_2_attack_100, original, ctgan_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan_dp_clip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c8582d696e415db7180288a48f1106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 81 potential matches (75%)!\n",
      "Identified 12549 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "ctgan_dp_clip = readCSV(dataPath+'ctgan_dp_clip.csv')\n",
    "ctgan_dp_clip_attack_100, ctgan_dp_clip_attack_75, ctgan_dp_clip_attack_50 = try_reidentification_noise(ctgan_dp_clip, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_dp_clip_attack_50_matches = get_matches(ctgan_dp_clip_attack_50, original, ctgan_dp_clip)\n",
    "ctgan_dp_clip_attack_75_matches = get_matches(ctgan_dp_clip_attack_75, original, ctgan_dp_clip)\n",
    "ctgan_dp_clip_attack_100_matches = get_matches(ctgan_dp_clip_attack_100, original, ctgan_dp_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan_dp_gan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not Run: Very slow due to the size of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_dp_gan = readCSV(dataPath+'ctgan_dp_gan.csv')\n",
    "ctgan_dp_gan_attack_100, ctgan_dp_gan_attack_75, ctgan_dp_gan_attack_50 = try_reidentification_noise(ctgan_dp_gan, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_dp_gan_attack_50_matches = get_matches(ctgan_dp_gan_attack_50, original, ctgan_dp_gan)\n",
    "ctgan_dp_gan_attack_75_matches = get_matches(ctgan_dp_gan_attack_75, original, ctgan_dp_gan)\n",
    "ctgan_dp_gan_attack_100_matches = get_matches(ctgan_dp_gan_attack_100, original, ctgan_dp_gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan_dp_sgd Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did not Run: very slow due to the size of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_dp_sgd = readCSV(dataPath+'ctgan_dp_sgd.csv')\n",
    "ctgan_dp_sgd_attack_100, ctgan_dp_sgd_attack_75, ctgan_dp_sgd_attack_50 = try_reidentification_noise(ctgan_dp_sgd, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgan_dp_sgd_attack_50_matches = get_matches(ctgan_dp_sgd_attack_50, original, ctgan_dp_sgd)\n",
    "ctgan_dp_sgd_attack_75_matches = get_matches(ctgan_dp_sgd_attack_75, original, ctgan_dp_sgd)\n",
    "ctgan_dp_sgd_attack_100_matches = get_matches(ctgan_dp_sgd_attack_100, original, ctgan_dp_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kg_ctgan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2d3ec1bee74261a9c99abd5182d7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 1248 potential matches (75%)!\n",
      "Identified 77436 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "kg_ctgan = readCSV(dataPath+'kg_ctgan.csv')\n",
    "kg_ctgan_attack_100, kg_ctgan_attack_75, kg_ctgan_attack_50 = try_reidentification_noise(kg_ctgan, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_ctgan_attack_50_matches = get_matches(kg_ctgan_attack_50, original, kg_ctgan)\n",
    "kg_ctgan_attack_75_matches = get_matches(kg_ctgan_attack_75, original, kg_ctgan)\n",
    "kg_ctgan_attack_100_matches = get_matches(kg_ctgan_attack_100, original, kg_ctgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Octgan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0a16c19c5d40a785f302fff3fe6d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 810 potential matches (75%)!\n",
      "Identified 65779 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "octgan = readCSV(dataPath+'octgan.csv')\n",
    "octgan_attack_100, octgan_attack_75, octgan_attack_50 = try_reidentification_noise(octgan, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "octgan_attack_50_matches = get_matches(octgan_attack_50, original, octgan)\n",
    "octgan_attack_75_matches = get_matches(octgan_attack_75, original, octgan)\n",
    "octgan_attack_100_matches = get_matches(octgan_attack_100, original, octgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pategan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b01f7a285a94c29b31af8f0e0205831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 121 potential matches (75%)!\n",
      "Identified 13553 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "pategan = readCSV(dataPath+'pategan.csv')\n",
    "pategan_attack_100, pategan_attack_75, pategan_attack_50 = try_reidentification_noise(pategan, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pategan_attack_50_matches = get_matches(pategan_attack_50, original, pategan)\n",
    "pategan_attack_75_matches = get_matches(pategan_attack_75, original, pategan)\n",
    "pategan_attack_100_matches = get_matches(pategan_attack_100, original, pategan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tablegan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a60373fad84b8687d36ad8cd7f7f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 428 potential matches (75%)!\n",
      "Identified 51065 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "tablegan = readCSV(dataPath+'tablegan.csv')\n",
    "tablegan_attack_100, tablegan_attack_75, tablegan_attack_50 = try_reidentification_noise(tablegan, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablegan_attack_50_matches = get_matches(tablegan_attack_50, original, tablegan)\n",
    "tablegan_attack_75_matches = get_matches(tablegan_attack_75, original, tablegan)\n",
    "tablegan_attack_100_matches = get_matches(tablegan_attack_100, original, tablegan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvae_1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924fb812d78842878ef3ace6117ce526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 151111 potential matches (75%)!\n",
      "Identified 85524 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "tvae_1 = readCSV(dataPath+'tvae_1.csv')\n",
    "tvae_1_attack_100, tvae_1_attack_75, tvae_1_attack_50 = try_reidentification_noise(tvae_1, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvae_1_attack_50_matches = get_matches(tvae_1_attack_50, original, tvae_1)\n",
    "tvae_1_attack_75_matches = get_matches(tvae_1_attack_75, original, tvae_1)\n",
    "tvae_1_attack_100_matches = get_matches(tvae_1_attack_100, original, tvae_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tvae_2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c548447a09184def9b63f25866fecd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches (100%)!\n",
      "Identified 258031 potential matches (75%)!\n",
      "Identified 225823 potential matches (50%)!\n"
     ]
    }
   ],
   "source": [
    "tvae_2 = readCSV(dataPath+'tvae_2.csv')\n",
    "tvae_2_attack_100, tvae_2_attack_75, tvae_2_attack_50 = try_reidentification_noise(tvae_2, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvae_2_attack_50_matches = get_matches(tvae_2_attack_50, original, tvae_2)\n",
    "tvae_2_attack_75_matches = get_matches(tvae_2_attack_75, original, tvae_2)\n",
    "tvae_2_attack_100_matches = get_matches(tvae_2_attack_100, original, tvae_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_reidentification_noise2(synth, net):\n",
    "    reident = pd.DataFrame(columns = synth.columns)\n",
    "    net_data = net.copy()\n",
    "    for index, row in tqdm(net_data.iterrows(), total=net_data.shape[0]):\n",
    "        # Here list all columns that are needed for reidentification\n",
    "        # will try to find a match between rows in the synthetic data and the information\n",
    "        # the attacker has (original network dataset)\n",
    "        filtered = synth.loc[(synth['Protocol'] == row['Protocol']) & (synth['Destination Port'] == row['Destination Port'])\n",
    "                             & (synth['Source Port'] == row['Source Port']) & (synth['Destination'] == row['Destination'])\n",
    "        ]#& (synth['Time'] == row['Time'])]\n",
    "        # potential match\n",
    "        if len(filtered) != 0:\n",
    "            reident = pd.concat([reident,filtered])\n",
    "        print(filtered)\n",
    "        break\n",
    "\n",
    "    print(f\"Identified {len(reident)} potential matches!\")\n",
    "    return reident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 778792/778792 [6:52:28<00:00, 31.47it/s]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 0 potential matches!\n"
     ]
    }
   ],
   "source": [
    "# Perform the attack - No matches found\n",
    "reident_attack = try_reidentification_noise2(df_synth, df_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [No., Time, Source, Source Port, Destination, Destination Port, Protocol, Length, Info]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(reident_attack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartnoise1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
